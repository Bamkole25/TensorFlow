{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "uci_breast_cancer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6rCa_bid9Z1",
        "colab_type": "text"
      },
      "source": [
        "# Using tf.keras to Predict Breast Cancer\n",
        "\n",
        "The University of California at Irvine (UCI) has released a large number of open-source data sets that are particularly useful for machine learning projects. One of them is the **Breast Cancer Wisconsin (Diagnostic) Data Set**. In this Colab, we will be using this dataset to train a tf.keras Sequential model that would predict the likelihood of a certain patient having either a *malignant(active/infectious)* or a *benign(dormant/inactive)* tumour based on certain parameters. Let's take a deeper look into the data. Start by downloading the *breast-cancer-wisconsin.data* and *breast-cancer-wisconsin.names* files and opening them in appropriate spreadsheet software/ text editors. \n",
        "\n",
        "![alt text](https://github.com/boronhub/breast_cancer_classifier/blob/master/images/data.jpg?raw=true)\n",
        "\n",
        "\n",
        "\n",
        "As soon as we open up the .data file,, we see that there are no labels. Thus, we can't really infer much from the data. So, for reference, we turn to the .names file.\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://github.com/boronhub/breast_cancer_classifier/blob/master/images/names.png?raw=true)\n",
        "\n",
        "We can see the data seperation of the benign and malignant tumours, and total number of entries. But most importantly, we see the various labels like clamp thickness, etc, which help us understand how the data is to be used when preparing it for input to the model.\n",
        "\n",
        "\n",
        "Let's get started with creating this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U21JujzWlYGe",
        "colab_type": "text"
      },
      "source": [
        "**Step 1: Importing necessary libraries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC-vckLGlfgK",
        "colab_type": "text"
      },
      "source": [
        "Make sure to use TensorFlow 2.x "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldSIk7wJWokO",
        "colab_type": "code",
        "outputId": "0f2cf818-6acd-4e11-ba17-1ccfefcab0b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PE50EGxOmBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDDxYuJqllvs",
        "colab_type": "text"
      },
      "source": [
        "**Step 2: Prepare the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU1heN9Ylrxp",
        "colab_type": "text"
      },
      "source": [
        "First, we import the .data file as csv from the official UCI Datasets Repository. Then, we need to manually define the column headers for the dataset using the .names file for reference. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J99GQ10BVdgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data')\n",
        "\n",
        "df.columns = ['id','clump_thickness','unif_cell_size','unif_cell_shape'\n",
        ",'marg_adhesion','single_epith_size','bare_nuclei','bland_chrom','norm_nucleoli','mitoses','class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m4JYG3dmAhG",
        "colab_type": "text"
      },
      "source": [
        "We drop the 'id' column, as it would not affect the identity of the cancer in any way. The dataset also has a few missing values (denoted by '?'), that we replace with false negatives so that particular entry is treated as an outlier.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cvjRt5YWUrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['id'], inplace=True, axis=1)\n",
        "df.replace('?', -99999, inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgH_ap57mZg0",
        "colab_type": "text"
      },
      "source": [
        "We see from the .names file that in the 'class' column, 2 is used for benign,and 4 for malignant. Remap these to 0 and 1 resectively for easier interpretation of the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuzFc3PZmY8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['class'] = df['class'].map(lambda x: 1 if x == 4 else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz_ru3hum31N",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at our dataset so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11OoFs_bDQG",
        "colab_type": "code",
        "outputId": "8fb29848-42a6-4197-e66c-bf27209a9472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clump_thickness</th>\n",
              "      <th>unif_cell_size</th>\n",
              "      <th>unif_cell_shape</th>\n",
              "      <th>marg_adhesion</th>\n",
              "      <th>single_epith_size</th>\n",
              "      <th>bare_nuclei</th>\n",
              "      <th>bland_chrom</th>\n",
              "      <th>norm_nucleoli</th>\n",
              "      <th>mitoses</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   clump_thickness  unif_cell_size  ...  mitoses  class\n",
              "0                5               4  ...        1      0\n",
              "1                3               1  ...        1      0\n",
              "2                6               8  ...        1      0\n",
              "3                4               1  ...        1      0\n",
              "4                8              10  ...        1      1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjItUNW4nEno",
        "colab_type": "text"
      },
      "source": [
        "**Step 3: Splitting the dataset**\n",
        "\n",
        "\n",
        "Once the data is ready, we need to seperate what we will be used as prediction labels (here it is the 'class' column) and as the parameters, which would be the rest of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLHWEO_PWkPO",
        "colab_type": "code",
        "outputId": "19b2f95c-eee2-4398-f49d-167b0715256d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = np.array(df.drop(['class'], axis=1))\n",
        "y = np.array(df['class'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(698, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezk7tc-hntJ6",
        "colab_type": "text"
      },
      "source": [
        "As with any model, we need to provide both a Training set, and a Validation, or a Test set. We can easily do this using the sklearn.train_test_split() function from the sklearn library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdUBgonOWxUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1clCFxQn_s7",
        "colab_type": "text"
      },
      "source": [
        "tf.keras models do not take NumPy arrays as inputs, which is what our input consists of until now. Using tf.convert_to_tensor(), we can easily convert these arrays into usable Tensors of the required size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4O-v4-fXFl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
        "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkq5CLSioT5l",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-jEm5HnoWWM",
        "colab_type": "text"
      },
      "source": [
        "Let's look a single entry from our training Tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvucnxVTMaKF",
        "colab_type": "code",
        "outputId": "7ba94673-7b01-4d1f-c2f6-c973ecb0bae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=float32, numpy=array([ 5.,  6.,  6.,  8.,  6., 10.,  4., 10.,  4.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-S-cvrYogsB",
        "colab_type": "text"
      },
      "source": [
        "**Step 4: Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_oKerg4YAnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(9, activation='sigmoid', input_shape=(9,)))\n",
        "model.add(Dense(27, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(54, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(27, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjS-XzkUY3qO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_logarithmic_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1929HnlZN89",
        "colab_type": "code",
        "outputId": "83bc448b-fa3f-4368-e422-f13f8f15eb46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "model.fit(x_train,y_train,batch_size=64,epochs=5,verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 558 samples, validate on 140 samples\n",
            "Epoch 1/5\n",
            "558/558 [==============================] - 1s 1ms/sample - loss: 0.1102 - val_loss: 0.1167\n",
            "Epoch 2/5\n",
            "558/558 [==============================] - 0s 81us/sample - loss: 0.1118 - val_loss: 0.1147\n",
            "Epoch 3/5\n",
            "558/558 [==============================] - 0s 73us/sample - loss: 0.1113 - val_loss: 0.1147\n",
            "Epoch 4/5\n",
            "558/558 [==============================] - 0s 73us/sample - loss: 0.1108 - val_loss: 0.1152\n",
            "Epoch 5/5\n",
            "558/558 [==============================] - 0s 67us/sample - loss: 0.1097 - val_loss: 0.1151\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f17d431e908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAjjv3mcoqWy",
        "colab_type": "text"
      },
      "source": [
        "**Step 5: Finishing Up**\n",
        "\n",
        "Using model.evaluate() with the validation set, we can finally figure out the accuracy of our model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4wMll-mZ40t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = model.evaluate(x_test, y_test, verbose=1, batch_size=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv21HEugmwiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Final acccuracy of the model is {}\".format(100-loss*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}