{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "# TinyImageNet Custom ResNet\n",
    "\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/template/notebook.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/template/notebook.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "## Overview\n",
    "{TODO: Fill in detailed info of what this accomplishes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNbeBoBWsDfa"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBluBf7GsDfb"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "! pip install -q tensorflow-gpu==2.0.0-beta1\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "print(f'{tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnv2z7-O2clU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import ZeroPadding2D, Activation, Flatten, add\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, SeparableConv2D\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qT8LP0hfsDfi"
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "\n",
    "import os\n",
    "download_path = os.getcwd()\n",
    "    \n",
    "import pathlib\n",
    "path = tf.keras.utils.get_file('tiny-imagenet-200.zip', extract=True, \n",
    "                               cache_subdir=download_path,\n",
    "                               origin='http://cs231n.stanford.edu/tiny-imagenet-200.zip')\n",
    "\n",
    "data_dir = pathlib.Path(path).with_suffix('')\n",
    "\n",
    "TRAIN = data_dir/\"train\"\n",
    "VAL = data_dir/\"val/images\"\n",
    "VAL_ANNOT = data_dir/'val/val_annotations.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-SQU5PLsDfn"
   },
   "source": [
    "## Image augmentation and image generators\n",
    "- The function below returns the generators for the ImageDataGenerator objects we will use to train and validate our ResNet model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGSBMQVqsDfo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "val_data = pd.read_csv(VAL_ANNOT , sep='\\t', names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
    "val_data.drop(['X','Y','H', 'W'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def train_val_gen(train_target=64, train_batch=64, val_target=64, val_batch=64):\n",
    "\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=18, # Rotation Angle\n",
    "            zoom_range=0.15,  # Zoom Range\n",
    "            width_shift_range=0.2, # Width Shift\n",
    "            height_shift_range=0.2, # Height Shift\n",
    "            shear_range=0.15,  # Shear Range\n",
    "            horizontal_flip=True, # Horizontal Flip\n",
    "            fill_mode=\"reflect\", # Fills empty with reflections\n",
    "            brightness_range=[0.4, 1.6]  # Increasing/decreasing brightness\n",
    "    )\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "                TRAIN,\n",
    "                target_size=(train_target, train_target),\n",
    "                batch_size=train_batch,\n",
    "                class_mode='categorical')\n",
    "\n",
    "        val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        val_generator = val_datagen.flow_from_dataframe(\n",
    "            val_data, directory=VAL, \n",
    "            x_col='File', \n",
    "            y_col='Class', \n",
    "            target_size=(val_target, val_target),\n",
    "            color_mode='rgb', \n",
    "            class_mode='categorical', \n",
    "            batch_size=val_batch, \n",
    "            shuffle=False, \n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WlmlEVva1lgv"
   },
   "source": [
    "## Defining callbacks to employ different training strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSzYk0oH10mv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fhrD1MEvsDft"
   },
   "source": [
    "## Custom ResNet that uses Pre-Activation and BottleNeck Blocks with SeparableConv2D\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "-  We use 1x1 to increase the number of channels is to create a wider model with minimum increase in trainable parameters.\n",
    "- This [reserach paper](https://arxiv.org/abs/1812.01187) documents improved accuracy with AveragePooling2D in the shortcut connection. This model showed a performance drop and hence was replaced with a 1x1 convolution.\n",
    "- Uses SeparableConv2D rather than vanilla Conv2D to reduce the nmber of parameters and make the model feasible to train on constrained environments like Google colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cNdKeWjwsDfz"
   },
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "\n",
    "    def residual_module(data, K, stride, chanDim, red=False, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "        shortcut = data\n",
    "\n",
    "        bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom, beta_initializer=\"zeros\", gamma_initializer=\"ones\")(data)\n",
    "        act1 = Activation(\"relu\")(bn1)\n",
    "        conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "        bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom, beta_initializer=\"zeros\", gamma_initializer=\"ones\")(conv1)\n",
    "        act2 = Activation(\"relu\")(bn2)\n",
    "        conv2 = SeparableConv2D(int(K * 0.25), (3, 3), strides=stride, padding=\"same\", use_bias=False, depthwise_regularizer=l2(reg), depthwise_initializer='glorot_uniform')(act2)\n",
    "\n",
    "        bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom, beta_initializer=\"zeros\", gamma_initializer=\"ones\")(conv2)\n",
    "        act3 = Activation(\"relu\")(bn3)\n",
    "        conv3 = Conv2D(K, (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act3)\n",
    "\n",
    "        if red and stride == (2,2):\n",
    "            shortcut = AveragePooling2D((2,2))(bn1)\n",
    "\n",
    "        shortcut = Conv2D(K, (1,1))(shortcut)\n",
    "        x = add([conv3, shortcut])\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def build(width, height, depth, classes, stages, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "        inputs = tf.keras.Input(shape=inputShape)\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom, beta_initializer=\"zeros\", gamma_initializer=\"ones\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SeparableConv2D(64, (3, 3), use_bias=False, padding=\"same\", depthwise_regularizer=l2(reg), depthwise_initializer='glorot_uniform')(x)\n",
    "        x = SeparableConv2D(128, (3, 3), use_bias=False, padding=\"same\", depthwise_regularizer=l2(reg), depthwise_initializer='glorot_uniform')(x)\n",
    "        x = SeparableConv2D(256, (3, 3), use_bias=False, padding=\"same\", depthwise_regularizer=l2(reg), depthwise_initializer='glorot_uniform')(x)\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom, beta_initializer=\"zeros\", gamma_initializer=\"ones\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = ZeroPadding2D((1, 1))(x)\n",
    "        x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "        for i in range(0, len(stages)):\n",
    "            stride = (1, 1) if i == 0 else (2, 2)\n",
    "            x = ResNet.residual_module(x, filters[i], stride, chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "            for j in range(0, stages[i] - 1):\n",
    "                x = ResNet.residual_module(x, filters[i], (1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(200, (1,1), kernel_regularizer=l2(reg))(x)\n",
    "        x = GlobalAveragePooling2D('channels_last')(x)\n",
    "        x = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = tf.keras.Model(inputs, x, name=\"resnet\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKVErJnbsDf5"
   },
   "outputs": [],
   "source": [
    "model = ResNet.build(None, None, 3, 200, (3, 4, 6), (64, 128, 256, 512), reg=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UD15cK08sDf-"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H9GdQWfCsDgE"
   },
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kib6v8vhsDgI"
   },
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999, epsilon=0.1, amsgrad=False)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rwwKT2EsDgO"
   },
   "source": [
    "## Using fit_generator to train the model\n",
    "ImageDataGenerator is best suited for augmenting images on the fly and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ztTE-5SJ83jy"
   },
   "outputs": [],
   "source": [
    "train_gen, val_gen = train_val_gen(train_target=16, train_batch=64, val_target=64, val_batch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_paZU0BAsDgP"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "  train_gen,\n",
    "  steps_per_epoch=100000 // 64,\n",
    "  validation_data=val_gen,\n",
    "  validation_steps=10000 // 64,\n",
    "  epochs=20,\n",
    "  max_queue_size=64 * 2,\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YytXkT3CLYI"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filepath = \"/content/epoch_20.hdf5\"\n",
    "\n",
    "model.save(\n",
    "    filepath,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True\n",
    ")\n",
    "\n",
    "# Load it again to continue training\n",
    "model = tf.keras.models.load_model(\n",
    "    filepath,\n",
    "    custom_objects=None,\n",
    "    compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-bTMEzKN-g8"
   },
   "outputs": [],
   "source": [
    "train_gen, val_gen = train_val_gen(train_target=32, train_batch=64, val_target=64, val_batch=64)\n",
    "\n",
    "model.fit_generator(\n",
    "  train_gen,\n",
    "  steps_per_epoch=100000 // 64,\n",
    "  validation_data=val_gen,\n",
    "  validation_steps=10000 // 64,\n",
    "  epochs=20,\n",
    "  max_queue_size=128,\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MbQZYeSnJHx"
   },
   "outputs": [],
   "source": [
    "filepath = \"/content/epoch_40.hdf5\"\n",
    "\n",
    "model.save(\n",
    "    filepath,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True\n",
    ")\n",
    "\n",
    "# Load it again to continue training\n",
    "model = tf.keras.models.load_model(\n",
    "    filepath,\n",
    "    custom_objects=None,\n",
    "    compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-6IvpOvJNFC"
   },
   "outputs": [],
   "source": [
    "train_gen, val_gen = train_val_gen(train_target=64, train_batch=64, val_target=64, val_batch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XvA_nhdnWh9"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "  train_gen,\n",
    "  steps_per_epoch=100000 // 64,\n",
    "  validation_data=val_gen,\n",
    "  validation_steps=10000 // 64,\n",
    "  epochs=20,\n",
    "  max_queue_size=64,\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSq0SvRoJYot"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filepath = \"/content/epoch_60.hdf5\"\n",
    "\n",
    "model.save(\n",
    "    filepath,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tk1_tjpQTuO2"
   },
   "outputs": [],
   "source": [
    "filepath = \"/content/epoch_60.hdf5\"\n",
    "\n",
    "# Load it again to continue training\n",
    "model = tf.keras.models.load_model(\n",
    "    filepath,\n",
    "    custom_objects=None,\n",
    "    compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_poZQLCTkpR"
   },
   "outputs": [],
   "source": [
    "train_gen, val_gen = train_val_gen(train_target=64, train_batch=64, val_target=64, val_batch=64)\n",
    "\n",
    "model.fit_generator(\n",
    "  train_gen,\n",
    "  steps_per_epoch=100000 // 64,\n",
    "  validation_data=val_gen,\n",
    "  validation_steps=10000 // 64,\n",
    "  epochs=20,\n",
    "  max_queue_size=64,\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uvX-lzEMUDHq"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filepath = \"/content/epoch_80.hdf5\"\n",
    "\n",
    "model.save(\n",
    "    filepath,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqVK3Hh745Ca"
   },
   "outputs": [],
   "source": [
    "# Load it again to continue training\n",
    "model = tf.keras.models.load_model(\n",
    "    filepath,\n",
    "    custom_objects=None,\n",
    "    compile=True\n",
    ")\n",
    "\n",
    "train_gen, val_gen = train_val_gen(train_target=64, train_batch=64, val_target=64, val_batch=64)\n",
    "\n",
    "model.fit_generator(\n",
    "  train_gen,\n",
    "  steps_per_epoch=100000 // 64,\n",
    "  validation_data=val_gen,\n",
    "  validation_steps=10000 // 64,\n",
    "  epochs=20,\n",
    "  max_queue_size=64,\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwZkcCnEsDgU"
   },
   "source": [
    "## List of references for easy lookup\n",
    "\n",
    "---\n",
    "\n",
    "1. Building blocks of interpretability: [Link](https://distill.pub/2018/building-blocks/) (Holy Grail of Intuition!)\n",
    "2. Deep Residual Learning for image classification: [Link](https://arxiv.org/abs/1512.03385) (Resnet Paper)\n",
    "3. Bag of tricks for image classification: [Link](https://arxiv.org/abs/1812.01187) (Tweaks and tricks to Resnet for increased performance paper)\n",
    "2. Imbalanced Deep Learning by Minority Class\n",
    "Incremental Rectification: [Link](https://arxiv.org/pdf/1804.10851.pdf) (Selectively Sampling Data paper)\n",
    "2. Improved Regularization of Convolutional Neural Networks with Cutout: [Link](https://arxiv.org/pdf/1708.04552.pdf) (Cutout/Occlusion Augmentation paper)\n",
    "3. Survey of resampling techniques for improving\n",
    "classification performance in unbalanced datasets [Link](https://arxiv.org/pdf/1608.06048v1.pdf) (Resampling paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LsqH9BNfLDi2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Tce3stUlHN0L"
   ],
   "name": "tiny_imagenet_custom_resnet.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
