{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "# TinyImageNet Custom ResNet\n",
    "\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/template/notebook.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/template/notebook.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "## Overview\n",
    "{TODO: Fill in detailed info of what this accomplishes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q tensorflow==2.0.0-beta1\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "print(f'{tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "download_path = os.getcwd()\n",
    "    \n",
    "path = tf.keras.utils.get_file('tiny-imagenet-200.zip', extract=True, cache_subdir=download_path,\n",
    "                               origin='http://cs231n.stanford.edu/tiny-imagenet-200.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image augmentation and image generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "val_data = pd.read_csv(VAL_ANNOT , sep='\\t', names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
    "val_data.drop(['X','Y','H', 'W'], axis=1, inplace=True)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=18, # Rotation Angle\n",
    "        zoom_range=0.15,  # Zoom Range\n",
    "        width_shift_range=0.2, # Width Shift\n",
    "        height_shift_range=0.2, # Height Shift\n",
    "        shear_range=0.15,  # Shear Range\n",
    "        horizontal_flip=True, # Horizontal Flip\n",
    "        fill_mode=\"reflect\", # Fills empty with reflections\n",
    "        brightness_range=[0.4, 1.6],  # Increasing/decreasing brightness\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=128,\n",
    "        class_mode='categorical')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_data, directory=VAL, \n",
    "    x_col='File', \n",
    "    y_col='Class', \n",
    "    target_size=(64, 64),\n",
    "    color_mode='rgb', \n",
    "    class_mode='categorical', \n",
    "    batch_size=128, \n",
    "    shuffle=False, \n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layered ResNet that uses Pre-Activated Layers and BottleNeck Blocks with SeparableConv2D\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "-  The reason to use 1x1 to increase the number of channels is to create a wider model with minimum increase in trainable parameters\n",
    "- I initially replaced stride by 2 in the shortcut connections with AveragePooling2D but saw a performance drop and so reverted back (Trained from scratch again!)\n",
    "- Uses SeparableConv2D rather than vanilla Conv2D and this drastically reduced the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, SeparableConv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import ZeroPadding2D, Activation, Flatten, add\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    \n",
    "    @staticmethod\n",
    "    def residual_block(data, K, stride, chanDim, red=False, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "        shortcut = data\n",
    "\n",
    "        bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(data)\n",
    "        act1 = Activation(\"relu\")(bn1)\n",
    "        conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "        bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv1)\n",
    "        act2 = Activation(\"relu\")(bn2)\n",
    "        conv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride, padding=\"same\", use_bias=False, kernel_regularizer=l2(reg))(act2)\n",
    "\n",
    "        bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv2)\n",
    "        act3 = Activation(\"relu\")(bn3)\n",
    "        conv3 = Conv2D(K, (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act3)\n",
    "\n",
    "        if red:\n",
    "            shortcut = Conv2D(K, (1, 1), strides=stride, use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "        x = add([conv3, shortcut])\n",
    "\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, stages, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "        inputs = tf.keras.Input(shape=inputShape)\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(inputs)\n",
    "\n",
    "        x = Conv2D(filters[0], (5, 5), use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = ZeroPadding2D((1, 1))(x)\n",
    "        x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "        for i in range(0, len(stages)):\n",
    "            stride = (1, 1) if i == 0 else (2, 2)\n",
    "            x = ResNet.residual_block(x, filters[i + 1], stride, chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "            for j in range(0, stages[i] - 1):\n",
    "                x = ResNet.residual_block(x, filters[i + 1], (1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
    "\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = AveragePooling2D((8, 8))(x)\n",
    "  \n",
    "        x = Conv2D(200, (1,1), kernel_regularizer=l2(reg))(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = tf.keras.Model(inputs, x, name=\"resnet\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet.build(64, 64, 3, 200, (3, 4, 6), (64, 128, 256, 512), reg=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using fit_generator to train the model\n",
    "ImageDataGenerator is best suited for augmenting images on the fly and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "  train_generator,\n",
    "  steps_per_epoch=100000 // 64,\n",
    "  validation_data=val_generator,\n",
    "  validation_steps=10000 // 64,\n",
    "  epochs=5,\n",
    "  max_queue_size=64 * 2,\n",
    "  callbacks=callbacks, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of references for easy lookup\n",
    "\n",
    "---\n",
    "\n",
    "1. Building blocks of interpretability: [Link](https://distill.pub/2018/building-blocks/) (Holy Grail of Intuition!)\n",
    "2. Deep Residual Learning for image classification: [Link](https://arxiv.org/abs/1512.03385) (Resnet Paper)\n",
    "3. Bag of tricks for image classification: [Link](https://arxiv.org/abs/1812.01187) (Tweaks and tricks to Resnet for increased performance paper)\n",
    "2. Imbalanced Deep Learning by Minority Class\n",
    "Incremental Rectification: [Link](https://arxiv.org/pdf/1804.10851.pdf) (Selectively Sampling Data paper)\n",
    "2. Improved Regularization of Convolutional Neural Networks with Cutout: [Link](https://arxiv.org/pdf/1708.04552.pdf) (Cutout/Occlusion Augmentation paper)\n",
    "3. Survey of resampling techniques for improving\n",
    "classification performance in unbalanced datasets [Link](https://arxiv.org/pdf/1608.06048v1.pdf) (Resampling paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UhNtHfuxCGVy"
   },
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKhmFeraTdEI"
   },
   "source": [
    "For general instructions on how to write docs for Tensorflow see [Writing TensorFlow Documentation](https://www.tensorflow.org/community/documentation).\n",
    "\n",
    "The tips below are specific to notebooks for tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2V22fKegUtF9"
   },
   "source": [
    "### General\n",
    "\n",
    "* Include the collapsed license at the top (this uses Colab's \"Form\" mode to hide the cells).\n",
    "* Only include a single `H1` title.\n",
    "* Include the button-bar immediately under the `H1`.\n",
    "* Include an overview section before any code.\n",
    "* Put all your installs and imports in a setup section.\n",
    "* Always include the three `__future__` imports.\n",
    "* Save the notebook with the Table of Contents open.\n",
    "* Write python3 compatible code.\n",
    "* Keep cells small (~max 20 lines).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YrsKXcPRUvK9"
   },
   "source": [
    "### Working in GitHub\n",
    "\n",
    "* Be consistent about how you save your notebooks, otherwise the JSON-diffs will be a mess.\n",
    "\n",
    "* This notebook has the \"Omit code cell output when saving this notebook\" option set. GitHub refuses to diff notebooks with large diffs (inline images).\n",
    "\n",
    "* [reviewnb.com](http://reviewnb.com) may help. You can access it using this bookmarklet:\n",
    "\n",
    "  ```\n",
    "javascript:(function(){ window.open(window.location.toString().replace(/github\\.com/, 'app.reviewnb.com').replace(/files$/,\"\")); })()\n",
    " ```\n",
    " \n",
    "* To open a GitHub notebook in Colab use the [Open in Colab](https://chrome.google.com/webstore/detail/open-in-colab/iogfkhleblhcpcekbiedikdehleodpjo) extension (or make a bookmarklet).\n",
    "  \n",
    "* The easiest way to edit a notebook in GitHub is to open it with Colab from the branch you want to edit. Then use File --> Save a copy in GitHub, which will save it back to the branch you opened it from.\n",
    "\n",
    "* For PRs it's helpful to post a direct Colab link to the PR head: https://colab.research.google.com/github/{user}/{repo}/blob/{branch}/{path}.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QKp40qS-DGEZ"
   },
   "source": [
    "### Code Style\n",
    "\n",
    "\n",
    "* Notebooks are for people. Write code optimized for clarity.\n",
    "\n",
    "* Demonstrate small parts before combining them into something more complex. Like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KtylpxOmceaC"
   },
   "outputs": [],
   "source": [
    "#Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(None, 5)),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMOeXVmbdilM"
   },
   "outputs": [],
   "source": [
    "# Run the model on a single batch of data, and inspect the output.\n",
    "result = model(tf.constant(np.random.randn(10,5), dtype = tf.float32)).numpy()\n",
    "\n",
    "print(\"min:\", result.min())\n",
    "print(\"max:\", result.max())\n",
    "print(\"mean:\", result.mean())\n",
    "print(\"shape:\", result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U82B_tH2d294"
   },
   "outputs": [],
   "source": [
    "# Compile the model for training\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3-lzxbCZi-H"
   },
   "source": [
    "* Keep examples quick. Use small datasets, or small slices of datasets. You don't need to train to convergence, train until it's obvious it's making progress.\n",
    "\n",
    "* For a large example, don't try to fit all the code in the notebook. Add python files to tensorflow examples, and in the noptebook run: `!pip install git+https://github.com/tensorflow/examples`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJdqBNBbS78n"
   },
   "source": [
    "### Code content\n",
    "\n",
    "Use the highest level API that gets the job done (unless the goal is to demonstrate the low level API).\n",
    "\n",
    "Use `keras.Sequential` > keras functional api > keras model subclassing > ...\n",
    "\n",
    "Use  `model.fit` > `model.train_on_batch` > manual `GradientTapes`.\n",
    "\n",
    "Use eager-style code.\n",
    "\n",
    "Use `tensorflow_datasets` and `tf.data` where possible.\n",
    "\n",
    "Avoid `compat.v1`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78HBT9cQXJko"
   },
   "source": [
    "### Text\n",
    "\n",
    "* Use an imperative style. \"Run a batch of images through the model.\"\n",
    "\n",
    "* Use sentence case in titles/headings. \n",
    "\n",
    "* Use short titles/headings: \"Download the data\", \"Build the Model\", \"Train the model\".\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Tce3stUlHN0L"
   ],
   "last_runtime": {
    "build_target": "//learning/brain/python/client:colab_notebook",
    "kind": "private"
   },
   "name": "notebook.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
